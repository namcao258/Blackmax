<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="Shape-Changing Soft Robotic Skin with Vision-based Tactile Sensing for Human-Robot Interaction" name="description"/>
<meta content="Representation Learning, Tactile Sensing, Imitation Learning" name="keywords"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>Shape-Changing Soft Robotic Skin with Vision-based Tactile Sensing for Human-Robot Interaction</title>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
<link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet"/>
<link href="./static/css/bulma.min.css" rel="stylesheet"/>
<link href="./static/css/bulma-carousel.min.css" rel="stylesheet"/>
<link href="./static/css/bulma-slider.min.css" rel="stylesheet"/>
<link href="./static/css/fontawesome.all.min.css" rel="stylesheet"/>
<link href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" rel="stylesheet"/>
<link href="./static/css/index.css" rel="stylesheet"/>
<link href="./static/images/favicon.png" rel="icon"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script defer="" src="./static/js/fontawesome.all.min.js"></script>
<script src="./static/js/bulma-carousel.min.js"></script>
<script src="./static/js/bulma-slider.min.js"></script>
<script src="./static/js/index.js"></script>
<style>
:root {
  --highlight: #3F72AF;
  --highlight-light: #DBE2EF;
  --highlight-dark: #112D4E;
  --text-dark: #222;
  --background: #F9F7F7;
}

.hl {
  color: var(--highlight);
  font-weight: 600;
}

a {
  color: var(--highlight);
  text-decoration: none;
}

a:hover {
  color: var(--highlight-dark);
  text-decoration: underline;
}

.button.is-dark {
  background-color: var(--highlight-dark);
  border-color: var(--highlight-dark);
}

.button.is-dark:hover {
  background-color: var(--highlight);
  border-color: var(--highlight);
}

html {
  background-color: var(--background);
  color: var(--text-dark);
}
</style><style>
h1, h2, h3, h4, h5, h6 {
  color: var(--highlight-dark);
}

.publication-title {
  color: var(--highlight-dark);
}

.title.is-1, .title.is-2, .title.is-3 {
  color: var(--highlight-dark);
}
</style></head>
<body>
<section class="hero">
<div class="hero-body">
<div class="container is-max-desktop">
<div class="columns is-centered">
<div class="column has-text-centered">
<h1 class="title is-1 publication-title">Shape-Changing Soft Robotic Skin with Vision-based Tactile Sensing for Human-Robot Interaction</h1>
<div class="is-size-5 publication-authors">
<span class="author-block">
<a href="https://scholar.google.com/citations?user=cEKEYFAAAAAJ&hl=en&oi=sra">Nam Phuong Dam</a>,
            </span> 
<span class="author-block">
<a href="https://quan-luu.github.io/">Quan Khanh Luu</a>,
            </span>
<span class="author-block">
<span class="author-block">
<a href="https://fp.jaist.ac.jp/public/Default2.aspx?id=669&l=1">Van Anh Ho</a>
            </span>
</div>
<div class="is-size-3 publication-authors">
<span class="author-block">Japan Advanced Institue of Science and Technology (JAIST), Japan</span>
</div>
<div class="column has-text-centered">
<div class="publication-links">
<!-- PDF Link. -->
<span class="link-block">
<a class="external-link button is-normal is-rounded is-dark" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10769816">
<span class="icon">
<i class="ai ai-arxiv"></i>
</span>
<span>Paper</span>
</a>
</span>
<!-- Video Link. -->
<span class="link-block">
<a class="external-link button is-normal is-rounded is-dark" href="https://youtu.be/dFgZLUpeWw4">
<span class="icon">
<i class="fab fa-youtube"></i>
</span>
<span>Video</span>
</a>
</span>
<!-- Code Link. -->
<span class="link-block">
<a class="external-link button is-normal is-rounded is-dark" href="https://github.com/namcao258/Blackmax_regression">
<span class="icon">
<i class="fab fa-github"></i>
</span>
<span>Code</span>
</a>
</span>
<!-- Dataset Link. -->
<!-- <span class="link-block">
<a class="external-link button is-normal is-rounded is-dark" href="">
<span class="icon">
<i class="far fa-images"></i>
</span>
<span>Data (Coming Soon)</span>
</a>
</span></div> -->
</div>
</div>
</div>
</div>
</div>
</section>
<section class="section">
<div class="container is-max-desktop">
<!-- Abstract. -->
<div class="columns is-centered has-text-centered">
<div class="column is-four-fifths">
<h2 class="title is-3">Abstract</h2>

<div class="content has-text-centered">
<img alt="First Page Image" id="teaser" src="./static/images/Proposed.PNG" width="50%"/>
<div class="content has-text-justified">
<br>
<p>
    Recent developments of vision-based tactile sensors primarily focus on small-sized and fixed-structured robot bodies, while the application of this sensing technique for whole-body, shape-changing robots remains a challenge. To address this problem, this study introduces a soft, changeable structured robot with integrated whole-body tactile sensing. The proposed robot system features a compact mechanism for adjusting the robotâ€™s height, and a camera system for vision-based tactile sensing, which are collectively covered by a marker-embedded soft robot skin. Additionally, a data-driven tactile sensing approach is developed to enable the robot to detect contacts across the entire robot body with varying heights. The preliminary results and showcases demonstrate the promise of the proposed system in facilitating robot operations in unstructured environments and enhancing human-robot interaction scenarios.
</p>
</div>
</div>
</div>
<!--/ Abstract. -->

</div>
</section>

<!-- ProTac Section: Design Overview -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <h2 class="title is-3">Design and Fabrication</h2>
        <p class="is-size-5 has-text-justified" style="margin-top: 1rem;">
          ***********************************************
        </p>
      </div>
    </div>

    <!-- Inspiration Video
    <div class="box" style="margin-top: 2rem;">
      <h3 class="title is-4">Inspiration from Electrochromic Windows</h3>
      <p class="has-text-justified">
        ProTac draws inspiration from electrochromic windows, which regulate transparency using voltage. 
        This concept enables a switchable, vision-based sensing mechanism for soft robot bodies.
      </p>
      <div class="has-text-centered" style="margin-top: 1rem;">
        <video autoplay muted loop controls playsinline width="90%">
          <source src="videos/protac_inspiration.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div> -->

    <!-- Design Overview Video -->
    <div class="box" style="margin-top: 2rem;">
      <h3 class="title is-4">Internal Design and Construction</h3>
      <p class="has-text-justified">
        *************************************
      </p>
      <div class="has-text-centered" style="margin-top: 1rem;">
        <video autoplay muted loop controls playsinline width="90%">
          <source src="videos/Design.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
 </section>   

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <h2 class="title is-3">Working Principle</h2>
        <p class="is-size-5 has-text-justified" style="margin-top: 1rem;">
        ****************************************************
        </p>
      </div>
    </div>

    <!-- Working Principle Video -->
    <div class="box" style="margin-top: 2rem;">
      <h3 class="title is-4">Working Principle</h3>
      <p class="has-text-justified">
        *******************************************************
      </p>
      <div class="has-text-centered" style="margin-top: 1rem;">
        <video autoplay muted loop controls playsinline width="90%">
          <source src="videos/Interface.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <h2 class="title is-3">Showcases</h2>
        <p class="is-size-5 has-text-justified" style="margin-top: 1rem;">
          ***********************************************************
        </p>
      </div>
    </div>

    <!-- Working Principle Video -->
    <div class="box" style="margin-top: 2rem;">
      <h3 class="title is-4">Working Principle</h3>
      <p class="has-text-justified">
        <!-- ProTac operates in two modes: in the <span class="hl">opaque</span> state, it detects contact across the large-area skin using a deep neural network applied to marker-featured images; 
        in the <span class="hl">transparent</span> state, it performs proximity sensing via monocular depth estimation applied to see-through images.
        This switchable mechanism enables dual-mode perception in a single soft robot body. -->
      </p>
      <div class="has-text-centered" style="margin-top: 1rem;">
        <video autoplay muted loop controls playsinline width="90%">
          <source src="videos/Showcase.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
  </div>
</section>

<!-- End ProTac Sections -->

<!-- Related Work -->
<section class="section">
<div class="container is-max-desktop">
<div class="columns is-centered">
<div class="column is-full-width">
<h2 class="title is-3">Related Work</h2>
  <div class="content has-text-justified">
    <p class="is-size-5 has-text-justified" style="margin-top: 1rem;">
    ********************************************************
    </p>
  </div>

  <!-- Paper Card 1 -->
  <div id="protac" class="media" style="display: flex; align-items: center;">
    <figure class="media-left">
      <p class="image is-256x256">
        <video autoplay muted loop playsinline width="128" height="128" style="object-fit: cover;">
          <source src="https://quan-luu.github.io/tn/videos/protac_sensing.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </p>
    </figure>
    <div class="media-content">
      <p>
        <strong>Soft Robotic Link with Controllable Transparency for Vision-based Tactile and Proximity Sensing</strong><br>
        <span style="color: #3273dc;"> Quan Khanh Luu, Dinh Quang Nguyen, Nhan Huu Nguyen, Van Anh Ho</span><br>
        <span style="color: gray;">IEEE RoboSoft 2023</span><br>
        <a href="https://quan-luu.github.io/files/Soft_Robotic_Link_with_Controllable_Transparency_for_Visionbased_Tactile_and_Proximity_Sensing.pdf" target="_blank">[Paper]</a>
        <a href="https://github.com/Ho-lab-jaist/protac" target="_blank">[Code]</a>
        <a href="https://youtu.be/m8QzvDx_vpc?si=JKCnNxe6U-JkebbL" target="_blank">[Video]</a>
        <a href="https://quan-luu.github.io/files/bib/protac_robosoft.bib" target="_blank">[BibTeX]</a>
      </p>
      <p style="margin-top: 0.5rem;">
        This study presents ProTac, a novel soft robotic link with integrated tactile and proximity sensing.
      </p>
    </div>
  </div>

  <!-- Paper Card 2 -->
  <div id="simtacls" class="media" style="display: flex; align-items: center;">
    <figure class="media-left">
      <p class="image is-256x256">
        <video autoplay muted loop playsinline width="128" height="128" style="object-fit: cover;">
          <source src="https://quan-luu.github.io/tn/videos/taclink_simtacls.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </p>
    </figure>
    <div class="media-content">
      <p>
        <strong>Simulation, Learning, and Application of Vision-Based Tactile Sensing at Large Scale</strong><br>
        <span style="color: #3273dc;">Quan Khanh Luu, Nhan Huu Nguyen, Van Anh Ho</span><br>
        <span style="color: gray;">IEEE Transaction on Robotics (T-RO), 2023</span><br>
        <a href="https://quan-luu.github.io/files/Simulation_Learning_and_Application_of_Vision-Based_Tactile_Sensing_at_Large_Scale.pdf" target="_blank">[Paper]</a>
        <a href="https://github.com/Ho-lab-jaist/SimTacLS" target="_blank">[Code]</a>
        <a href="https://www.youtube.com/watch?v=NN2u8YBLITY" target="_blank">[Video]</a>
        <a href="https://quan-luu.github.io/files/bib/simtacls_tro23.bib" target="_blank">[BibTeX]</a>
      </p>
      <p style="margin-top: 0.5rem;">
        This study introduces SimTacLS, 
        a physics-informed simulation and learning pipeline designed for large-area soft vision-based tactile sensors.
      </p>
    </div>
  </div>

  <!-- Paper Card 3 -->
  <div id="taclink-control" class="media" style="display: flex; align-items: center;">
    <figure class="media-left">
      <p class="image is-256x256">
        <video autoplay muted loop playsinline width="128" height="128" style="object-fit: cover;">
          <source src="https://quan-luu.github.io/tn/videos/taclink_safety.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </p>
    </figure>
    <div class="media-content">
      <p>
        <strong>TacLink-Integrated Robot Arm toward Safe Human-Robot Interaction</strong><br>
        <span style="color: #3273dc;">Quan Khanh Luu, Alessandro Albini, Perla Maiolino, Van Anh Ho</span><br>
        <span style="color: gray;">IROS 2024</span><br>
        <a href="https://quan-luu.github.io/files/TacLink-Integrated_Robot_Arm_toward_Safe_Human-Robot_Interaction.pdf" target="_blank">[Paper]</a>
        <a href="https://github.com/Ho-lab-jaist/taclink-control" target="_blank">[Code]</a>
        <a href="https://quan-luu.github.io/videos/media/taclink_iros24.mp4" target="_blank">[Video]</a>
        <a href="https://quan-luu.github.io/files/bib/taclink_iros_luu_24.bib" target="_blank">[BibTeX]</a>
      </p>
      <p style="margin-top: 0.5rem;">
        This study explores the use of TacLink, a soft vision-based tactile link, 
        as a safety control mechanism that can potentially replace conventional rigid robot links and impact observers.
      </p>
    </div>
  </div>

  <!-- Paper Card 3 -->
  <div id="vi2tap" class="media" style="display: flex; align-items: center;">
    <figure class="media-left">
      <p class="image is-256x256">
        <video autoplay muted loop playsinline width="128" height="128" style="object-fit: cover;">
          <source src="https://quan-luu.github.io/tn/videos/vi2tap.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </p>
    </figure>
    <div class="media-content">
      <p>
        <strong>Vi2TaP: A Cross-Polarization Based Mechanism for Perception Transition in Tactile-Proximity Sensing with Applications to Soft Grippers</strong><br>
        <span style="color: #3273dc;"> Nhan Huu Nguyen, Nhat Minh Dinh Le, Quan Khanh Luu, Tuan Tai Nguyen, Van Anh Ho</span><br>
        <span style="color: gray;">IEEE Robotics and Automation Letters (RA-L), 2025 </span><br>
        <a href="https://quan-luu.github.io/files/Vi2TaP.pdf" target="_blank">[Paper]</a>
        <a href="https://youtu.be/apDyYN9bh5Y?si=iHJ3vZWWf-3ohmtK" target="_blank">[Video]</a>
        <a href="https://quan-luu.github.io/files/bib/vi2tap_ral.bib" target="_blank">[BibTeX]</a>
      </p>
      <p style="margin-top: 0.5rem;">
        This study introduces Vi2TaP, a cross-polarization-based multimodal soft gripper that seamlessly 
        switches between tactile and proximity sensing.
      </p>
    </div>
  </div>

</div>
</div>
</div>
</section>
<!-- End Related Work -->

<!-- BibTeX -->
<section class="section" id="BibTeX">
<div class="container is-max-desktop">
<div class="columns is-centered">
<div class="column is-full-width">
<h2 class="title is-3">BibTeX</h2>
    <!-- <pre><code>
@misc{luu2025manifeelbenchmarkingunderstandingvisuotactile,
  title        = {ManiFeel: Benchmarking and Understanding Visuotactile Manipulation Policy Learning},
  author       = {Quan Khanh Luu and Pokuang Zhou and Zhengtong Xu and Zhiyuan Zhang and Qiang Qiu and Yu She},
  year         = {2025},
  eprint       = {2505.18472},
  archivePrefix = {arXiv},
  primaryClass = {cs.RO},
  url          = {https://arxiv.org/abs/2505.18472}
}
    </code></pre> -->
</div>
</div>
</div>
</section>
<!-- End BibTeX -->

<footer class="footer">
<div class="container">
<div class="content has-text-centered">
<a class="external-link" disabled="" href="https://github.com/quan-luu">
<i class="fab fa-github"></i>
</a>
</div>
<div class="columns is-centered">
<div class="column is-8">
<div class="content">
<p>
            This website is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="license">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
<p>
            The template of this website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
</div>
</div>
</div>
</div>
</footer>

</body>
</html>